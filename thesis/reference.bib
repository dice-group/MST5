% Encoding: UTF-8

% Language model

% Transformers

@inproceedings{Transformers,
  title	= {Attention is All You Need},

  author	= {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},

  year	= {2017},

  URL	= {https://arxiv.org/pdf/1706.03762.pdf}
}

@misc{BERT,
  doi = {10.48550/ARXIV.1810.04805},
  
  url = {https://arxiv.org/abs/1810.04805},
  
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{DBLP:journals/corr/ZhuKZSUTF15,
  author    = {Yukun Zhu and
               Ryan Kiros and
               Richard S. Zemel and
               Ruslan Salakhutdinov and
               Raquel Urtasun and
               Antonio Torralba and
               Sanja Fidler},
  title     = {Aligning Books and Movies: Towards Story-like Visual Explanations
               by Watching Movies and Reading Books},
  journal   = {CoRR},
  volume    = {abs/1506.06724},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.06724},
  eprinttype = {arXiv},
  eprint    = {1506.06724},
  timestamp = {Mon, 13 Aug 2018 16:47:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZhuKZSUTF15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{mBERT,
  author = {Jacob Devlin},

  title = {Multilingual BERT},

  year = {2018},

  url = {https://github.com/ google-research/bert/blob/master/ multilingual.md.}
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@InProceedings{Winery,
  author    = {Oliver Kopp and others},
  
  booktitle = {Proceedings of 11\textsuperscript{th} International Conference on Service-Oriented Computing (ICSOC'13)},

  title     = {{Winery -- A Modeling Tool for {TOSCA}-based Cloud Applications}},

  year      = {2013},

  pages     = {700--704},

  publisher = {Springer Berlin Heidelberg},

  series    = {LNCS},

  volume    = {8274},

  doi       = {10.1007/978-3-642-45005-1_64},

  keywords  = {Cloud Applications; Modeling; TOSCA; Management; Portability},

}

@article{DBLP:journals/corr/abs-1910-10683,
  author    = {Colin Raffel and
               Noam Shazeer and
               Adam Roberts and
               Katherine Lee and
               Sharan Narang and
               Michael Matena and
               Yanqi Zhou and
               Wei Li and
               Peter J. Liu},
  title     = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text
               Transformer},
  journal   = {CoRR},
  volume    = {abs/1910.10683},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.10683},
  eprinttype = {arXiv},
  eprint    = {1910.10683},
  timestamp = {Fri, 05 Feb 2021 15:43:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-10683.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1805-12471,
  author    = {Alex Warstadt and
               Amanpreet Singh and
               Samuel R. Bowman},
  title     = {Neural Network Acceptability Judgments},
  journal   = {CoRR},
  volume    = {abs/1805.12471},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.12471},
  eprinttype = {arXiv},
  eprint    = {1805.12471},
  timestamp = {Mon, 13 Aug 2018 16:47:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-12471.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dolan-brockett-2005-automatically,
    title = "Automatically Constructing a Corpus of Sentential Paraphrases",
    author = "Dolan, William B.  and
      Brockett, Chris",
    booktitle = "Proceedings of the Third International Workshop on Paraphrasing ({IWP}2005)",
    year = "2005",
    url = "https://aclanthology.org/I05-5002",
}

@article{DBLP:journals/corr/abs-2010-11934,
  author    = {Linting Xue and
               Noah Constant and
               Adam Roberts and
               Mihir Kale and
               Rami Al{-}Rfou and
               Aditya Siddhant and
               Aditya Barua and
               Colin Raffel},
  title     = {mT5: {A} massively multilingual pre-trained text-to-text transformer},
  journal   = {CoRR},
  volume    = {abs/2010.11934},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11934},
  eprinttype = {arXiv},
  eprint    = {2010.11934},
  timestamp = {Tue, 27 Oct 2020 11:22:08 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11934.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1901-07291,
  author    = {Guillaume Lample and
               Alexis Conneau},
  title     = {Cross-lingual Language Model Pretraining},
  journal   = {CoRR},
  volume    = {abs/1901.07291},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.07291},
  eprinttype = {arXiv},
  eprint    = {1901.07291},
  timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-07291.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1911-02116,
  author    = {Alexis Conneau and
               Kartikay Khandelwal and
               Naman Goyal and
               Vishrav Chaudhary and
               Guillaume Wenzek and
               Francisco Guzm{\'{a}}n and
               Edouard Grave and
               Myle Ott and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {Unsupervised Cross-lingual Representation Learning at Scale},
  journal   = {CoRR},
  volume    = {abs/1911.02116},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.02116},
  eprinttype = {arXiv},
  eprint    = {1911.02116},
  timestamp = {Mon, 11 Nov 2019 18:38:09 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-02116.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1910-13461,
  author    = {Mike Lewis and
               Yinhan Liu and
               Naman Goyal and
               Marjan Ghazvininejad and
               Abdelrahman Mohamed and
               Omer Levy and
               Veselin Stoyanov and
               Luke Zettlemoyer},
  title     = {{BART:} Denoising Sequence-to-Sequence Pre-training for Natural Language
               Generation, Translation, and Comprehension},
  journal   = {CoRR},
  volume    = {abs/1910.13461},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.13461},
  eprinttype = {arXiv},
  eprint    = {1910.13461},
  timestamp = {Thu, 31 Oct 2019 14:02:26 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-13461.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2001-08210,
  author    = {Yinhan Liu and
               Jiatao Gu and
               Naman Goyal and
               Xian Li and
               Sergey Edunov and
               Marjan Ghazvininejad and
               Mike Lewis and
               Luke Zettlemoyer},
  title     = {Multilingual Denoising Pre-training for Neural Machine Translation},
  journal   = {CoRR},
  volume    = {abs/2001.08210},
  year      = {2020},
  url       = {https://arxiv.org/abs/2001.08210},
  eprinttype = {arXiv},
  eprint    = {2001.08210},
  timestamp = {Fri, 24 Jan 2020 15:00:57 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2001-08210.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2006-15020,
  author    = {Mike Lewis and
               Marjan Ghazvininejad and
               Gargi Ghosh and
               Armen Aghajanyan and
               Sida I. Wang and
               Luke Zettlemoyer},
  title     = {Pre-training via Paraphrasing},
  journal   = {CoRR},
  volume    = {abs/2006.15020},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.15020},
  eprinttype = {arXiv},
  eprint    = {2006.15020},
  timestamp = {Wed, 23 Sep 2020 10:33:27 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-15020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{RemBert,
  doi = {10.48550/ARXIV.2010.12821},
  
  url = {https://arxiv.org/abs/2010.12821},
  
  author = {Chung, Hyung Won and FÃ©vry, Thibault and Tsai, Henry and Johnson, Melvin and Ruder, Sebastian},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Rethinking embedding coupling in pre-trained language models},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{T5,
  doi = {10.48550/ARXIV.1910.10683},
  
  url = {https://arxiv.org/abs/1910.10683},
  
  author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{mT5,
  doi = {10.48550/ARXIV.2010.11934},
  
  url = {https://arxiv.org/abs/2010.11934},
  
  author = {Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {mT5: A massively multilingual pre-trained text-to-text transformer},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{GPT-2,
  title={Language Models are Unsupervised Multitask Learners},

  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},

  year={2019}
}

@misc{XLM,
  doi = {10.48550/ARXIV.1901.07291},
  
  url = {https://arxiv.org/abs/1901.07291},
  
  author = {Lample, Guillaume and Conneau, Alexis},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Cross-lingual Language Model Pretraining},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{XLM-R,
  doi = {10.48550/ARXIV.1911.02116},
  
  url = {https://arxiv.org/abs/1911.02116},
  
  author = {Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and GuzmÃ¡n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Unsupervised Cross-lingual Representation Learning at Scale},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{mBART,
  doi = {10.48550/ARXIV.1910.13461},
  
  url = {https://arxiv.org/abs/1910.13461},
  
  author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{mBART,
  doi = {10.48550/ARXIV.2001.08210},
  
  url = {https://arxiv.org/abs/2001.08210},
  
  author = {Liu, Yinhan and Gu, Jiatao and Goyal, Naman and Li, Xian and Edunov, Sergey and Ghazvininejad, Marjan and Lewis, Mike and Zettlemoyer, Luke},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Multilingual Denoising Pre-training for Neural Machine Translation},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{MARGE,
  doi = {10.48550/ARXIV.2006.15020},
  
  url = {https://arxiv.org/abs/2006.15020},
  
  author = {Lewis, Mike and Ghazvininejad, Marjan and Ghosh, Gargi and Aghajanyan, Armen and Wang, Sida and Zettlemoyer, Luke},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Pre-training via Paraphrasing},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1801.06146,
  doi = {10.48550/ARXIV.1801.06146},
  
  url = {https://arxiv.org/abs/1801.06146},
  
  author = {Howard, Jeremy and Ruder, Sebastian},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Universal Language Model Fine-tuning for Text Classification},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


% Knowledge graph

@article{10.1145/2629489,
    author = {Vrande\v{c}i\'{c}, Denny and Kr\"{o}tzsch, Markus},
    title = {Wikidata: A Free Collaborative Knowledgebase},
    year = {2014},
    issue_date = {October 2014},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {57},
    number = {10},
    issn = {0001-0782},
    url = {https://doi.org/10.1145/2629489},
    doi = {10.1145/2629489},
    abstract = {This collaboratively edited knowledgebase provides a common source of data for Wikipedia, and everyone else.},
    journal = {Commun. ACM},
    month = {sep},
    pages = {78â85},
    numpages = {8}
}


@inproceedings{10.1007/978-3-540-76298-0_52,
	address = {Berlin, Heidelberg},
	author = {Auer, S{\"o}ren and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
	booktitle = {The Semantic Web},
	editor = {Aberer, Karl and Choi, Key-Sun and Noy, Natasha and Allemang, Dean and Lee, Kyung-Il and Nixon, Lyndon and Golbeck, Jennifer and Mika, Peter and Maynard, Diana and Mizoguchi, Riichiro and Schreiber, Guus and Cudr{\'e}-Mauroux, Philippe},
	pages = {722--735},
	publisher = {Springer Berlin Heidelberg},
	title = {DBpedia: A Nucleus for a Web of Open Data},
	year = {2007}
}


@inproceedings{10.1007/978-3-030-49461-2_34,
	address = {Cham},
	author = {Pellissier Tanon, Thomas and Weikum, Gerhard and Suchanek, Fabian},
	booktitle = {The Semantic Web},
	editor = {Harth, Andreas and Kirrane, Sabrina and Ngonga Ngomo, Axel-Cyrille and Paulheim, Heiko and Rula, Anisa and Gentile, Anna Lisa and Haase, Peter and Cochez, Michael},
	pages = {583--596},
	publisher = {Springer International Publishing},
	title = {YAGO 4: A Reason-able Knowledge Base},
	year = {2020}}

@inproceedings{10.1145/1242572.1242667,
author = {Suchanek, Fabian M. and Kasneci, Gjergji and Weikum, Gerhard},
title = {Yago: A Core of Semantic Knowledge},
year = {2007},
isbn = {9781595936547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1242572.1242667},
doi = {10.1145/1242572.1242667},
abstract = {We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques.},
booktitle = {Proceedings of the 16th International Conference on World Wide Web},
pages = {697â706},
numpages = {10},
keywords = {wikipedia, WordNet},
location = {Banff, Alberta, Canada},
series = {WWW '07}
}

@book{Fellbaum1998,
  abstract = {WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets. The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains.},
  added-at = {2017-11-01T11:46:20.000+0100},
  address = {Cambridge, MA},
  biburl = {https://www.bibsonomy.org/bibtex/28472b4f9d7f2bfc4a97ffd4a023facc6/flint63},
  editor = {Fellbaum, Christiane},
  file = {eBook:1900-99/Fellbaum1998.pdf:PDF;MIT Press Product Page:http\://mitpress.mit.edu/books/wordnet:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/026206197X/:URL},
  groups = {public},
  interhash = {42daa1681607dd1d3f3234c605d84ec3},
  intrahash = {8472b4f9d7f2bfc4a97ffd4a023facc6},
  isbn = {978-0-262-06197-1},
  keywords = {01821 101 mitpress book shelf ai language processing ontology lexicon},
  publisher = {MIT Press},
  series = {Language, Speech, and Communication},
  timestamp = {2018-04-16T11:51:58.000+0200},
  title = {WordNet: An Electronic Lexical Database},
  username = {flint63},
  year = 1998
}

@article{10.1145/2844544,
    author = {Guha, R. V. and Brickley, Dan and Macbeth, Steve},
    title = {Schema.Org: Evolution of Structured Data on the Web},
    year = {2016},
    issue_date = {February 2016},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {59},
    number = {2},
    issn = {0001-0782},
    url = {https://doi.org/10.1145/2844544},
    doi = {10.1145/2844544},
    abstract = {Big data makes common schemas even more necessary.},
    journal = {Commun. ACM},
    month = {jan},
    pages = {44â51},
    numpages = {8}
}

@inproceedings{10.5555/2898607.2898816,
    author = {Carlson, Andrew and Betteridge, Justin and Kisiel, Bryan and Settles, Burr and Hruschka, Estevam R. and Mitchell, Tom M.},
    title = {Toward an Architecture for Never-Ending Language Learning},
    year = {2010},
    publisher = {AAAI Press},
    abstract = {We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.},
    booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
    pages = {1306â1313},
    numpages = {8},
    location = {Atlanta, Georgia},
    series = {AAAI'10}
}

@inproceedings{opencyc,
    author = {Matuszek, Cynthia and Cabral, John and Witbrock, Michael and DeOliveira, John},
    year = {2006},
    month = {01},
    pages = {44-49},
    title = {An Introduction to the Syntax and Content of Cyc.}
}

@paper{speer2017conceptnet,
    author = {Robyn Speer and Joshua Chin and Catherine Havasi},
    title = {ConceptNet 5.5: An Open Multilingual Graph of General Knowledge},
    conference = {AAAI Conference on Artificial Intelligence},
    year = {2017},
    pages = {4444--4451},
    keywords = {ConceptNet; knowledge graph; word embeddings},
    url = {http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972}
}

@article{OMCS,
    author = {Singh, Push},
    year = {2009},
    month = {04},
    pages = {},
    title = {The Public Acquisition of Commonsense Knowledge}
}

@inproceedings{bond-foster-2013-linking,
    title = "Linking and Extending an Open Multilingual {W}ordnet",
    author = "Bond, Francis  and
      Foster, Ryan",
    booktitle = "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P13-1133",
    pages = "1352--1362",
}



% Multilingual QA

@inproceedings{MT-KGQA,
author = {Perevalov, Aleksandr and Both, Andreas and Diefenbach, Dennis and Ngonga Ngomo, Axel-Cyrille},
title = {Can Machine Translation Be a Reasonable Alternative for Multilingual Question Answering Systems over Knowledge Graphs?},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3511940},
doi = {10.1145/3485447.3511940},
abstract = {Providing access to information is the main and most important purpose of the Web. However, despite available easy-to-use tools (e.g., search engines, chatbots, question answering) the accessibility is typically limited by the capability of using the English language. This excludes a huge amount of people. In this work, we discuss Knowledge Graph Question Answering (KGQA) systems that aim at providing natural language access to data stored in Knowledge Graphs (KG). While several KGQA systems have been proposed, only very few have dealt with a language other than English. In this work, we follow our research agenda of enabling speakers of any language to access the knowledge stored in KGs. Because of the lack of native support for many languages, we use machine translation (MT) tools to evaluate KGQA systems regarding questions in languages that are unsupported by a KGQA system. In total, our evaluation is based on 8 different languages (including some that never were evaluated before). For the intensive evaluation, we extend the QALD-9 dataset for KGQA with Wikidata queries and high-quality translations. The extension was done in a crowdsourcing manner by native speakers of the different languages. By using multiple KGQA systems for the evaluation, we were enabled to investigate and answer the main research question: âCan MT be an alternative for multilingual KGQA systems?â. The evaluation results demonstrated that the monolingual KGQA systems can be effectively ported to the new languages with MT tools.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {977â986},
numpages = {10},
keywords = {multilingual question answering, question answering dataset, machine translation, knowledge graph question answering},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{zhou-etal-2021-improving,
    title = "Improving Zero-Shot Cross-lingual Transfer for Multilingual Question Answering over Knowledge Graph",
    author = "Zhou, Yucheng  and
      Geng, Xiubo  and
      Shen, Tao  and
      Zhang, Wenqiang  and
      Jiang, Daxin",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.465",
    doi = "10.18653/v1/2021.naacl-main.465",
    pages = "5822--5834",
    abstract = "Multilingual question answering over knowledge graph (KGQA) aims to derive answers from a knowledge graph (KG) for questions in multiple languages. To be widely applicable, we focus on its zero-shot transfer setting. That is, we can only access training data in a high-resource language, while need to answer multilingual questions without any labeled data in target languages. A straightforward approach is resorting to pre-trained multilingual models (e.g., mBERT) for cross-lingual transfer, but there is a still significant gap of KGQA performance between source and target languages. In this paper, we exploit unsupervised bilingual lexicon induction (BLI) to map training questions in source language into those in target language as augmented training data, which circumvents language inconsistency between training and inference. Furthermore, we propose an adversarial learning strategy to alleviate syntax-disorder of the augmented data, making the model incline to both language- and syntax-independence. Consequently, our model narrows the gap in zero-shot cross-lingual transfer. Experiments on two multilingual KGQA datasets with 11 zero-resource languages verify its effectiveness.",
}
@inproceedings{pouran-ben-veyseh-2016-cross,
    title = "Cross-Lingual Question Answering Using Common Semantic Space",
    author = "Pouran Ben Veyseh, Amir",
    booktitle = "Proceedings of {T}ext{G}raphs-10: the Workshop on Graph-based Methods for Natural Language Processing",
    month = jun,
    year = "2016",
    address = "San Diego, CA, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-1403",
    doi = "10.18653/v1/W16-1403",
    pages = "15--19",
}
@misc{AMUSE,
  doi = {10.48550/ARXIV.1802.09296},
  
  url = {https://arxiv.org/abs/1802.09296},
  
  author = {Hakimov, Sherzod and Jebbara, Soufian and Cimiano, Philipp},
  
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {AMUSE: Multilingual Semantic Parsing for Question Answering over Linked Data},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {Creative Commons Zero v1.0 Universal}
}
@misc{https://doi.org/10.48550/arxiv.1803.00832,
  doi = {10.48550/ARXIV.1803.00832},
  
  url = {https://arxiv.org/abs/1803.00832},
  
  author = {Diefenbach, Dennis and Both, Andreas and Singh, Kamal and Maret, Pierre},
  
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Towards a Question Answering System over the Semantic Web},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{10.1007/978-3-319-98192-5_21,
	abstract = {In this paper we present Platypus, a natural language question answering system on Wikidata. Our platform can answer complex queries in several languages, using hybrid grammatical and template based techniques. Our demo allows users either to select sample questions, or formulate their own -- in any of the 3 languages that we currently support. A user can also try out our Twitter bot, which replies to any tweet that is sent to its account.},
	address = {Cham},
	author = {Pellissier Tanon, Thomas and de Assun{\c{c}}{\~a}o, Marcos Dias and Caron, Eddy and Suchanek, Fabian M.},
	booktitle = {The Semantic Web: ESWC 2018 Satellite Events},
	editor = {Gangemi, Aldo and Gentile, Anna Lisa and Nuzzolese, Andrea Giovanni and Rudolph, Sebastian and Maleshkova, Maria and Paulheim, Heiko and Pan, Jeff Z and Alam, Mehwish},
	isbn = {978-3-319-98192-5},
	pages = {111--116},
	publisher = {Springer International Publishing},
	title = {Demoing Platypus -- A Multilingual Question Answering Platform for Wikidata},
	year = {2018}
}
@ARTICLE{sgpt,  
    author={Rony, Md Rashad Al Hasan and Kumar, Uttam and Teucher, Roman and    Kovriguina, Liubov and Lehmann, Jens},  
    journal={IEEE Access},  
    title={SGPT: A Generative Approach for SPARQL Query Generation From Natural Language Questions},   
    year={2022},  
    volume={10},  
    number={},  
    pages={70712-70723},  
    doi={10.1109/ACCESS.2022.3188714}
}

@INPROCEEDINGS{9282949,  
    author={To, Nhuan D. and Reformat, Marek},  
    booktitle={2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},   
    title={Question-Answering System with Linguistic Terms over RDF Knowledge Graphs},   
    year={2020},  
    volume={},  
    number={},  
    pages={4236-4243},  
    doi={10.1109/SMC42975.2020.9282949}
}

@misc{https://doi.org/10.48550/arxiv.1910.09760,
  doi = {10.48550/ARXIV.1910.09760},
  
  url = {https://arxiv.org/abs/1910.09760},
  
  author = {Zheng, Weiguo and Zhang, Mei},
  
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Question Answering over Knowledge Graphs via Structural Query Patterns},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{panchbhai-2020,
    author = "Anand Panchbhai and Tommaso Soru and Edgard Marx",
    title = "Exploring Sequence-to-Sequence Models for {SPARQL} Pattern Composition",
    year = "2020",
    journal = "First Indo-American Knowledge Graph and Semantic Web Conference",
    url = "https://arxiv.org/abs/2010.10900",
}

@article{DBLP:journals/corr/abs-2201-08174,
  author    = {Aleksandr Perevalov and
               Xi Yan and
               Liubov Kovriguina and
               Longquan Jiang and
               Andreas Both and
               Ricardo Usbeck},
  title     = {Knowledge Graph Question Answering Leaderboard: {A} Community Resource
               to Prevent a Replication Crisis},
  journal   = {CoRR},
  volume    = {abs/2201.08174},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.08174},
  eprinttype = {arXiv},
  eprint    = {2201.08174},
  timestamp = {Fri, 01 Jul 2022 17:45:26 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-08174.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% dataset

@INPROCEEDINGS{qald9plus,  
    author={Perevalov, Aleksandr and Diefenbach, Dennis and Usbeck, Ricardo and Both, Andreas},  
    booktitle={2022 IEEE 16th International Conference on Semantic Computing (ICSC)},   
    title={QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia and Wikidata Translated by Native Speakers},   
    year={2022},  
    volume={},  
    number={},  
    pages={229-234},  
    doi={10.1109/ICSC52841.2022.00045}
}

@inproceedings{qald9,
    author = {Usbeck, Ricardo and Gusmita, Ria and Saleem, Muhammad and Ngonga Ngomo, Axel-Cyrille},
    year = {2018},
    month = {11},
    pages = {},
    title = {9th Challenge on Question Answering over Linked Data (QALD-9)}
}
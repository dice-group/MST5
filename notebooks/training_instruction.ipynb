{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model for exp9\n",
    "\n",
    "- use Wikidata knowledge graph\n",
    "- use mT5-XL as base model\n",
    "- pre-train on LC-QuAD 2.0 for 32 epochs\n",
    "- pre-train on QALD-9-Plus all languages for 15 epochs\n",
    "- with linguistic context in pre-training and fine-tuning\n",
    "- without entity knowledge\n",
    "- without padding, only add a `<pad>` token after each component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Please run all commands in the root of this repo__\n",
    "\n",
    "__All commands are tested on 3dfed server__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install miniconda on Linux\n",
    "\n",
    "```bash\n",
    "mkdir -p ~/miniconda3\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
    "bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
    "rm -rf ~/miniconda3/miniconda.sh\n",
    "~/miniconda3/bin/conda init bash\n",
    "~/miniconda3/bin/conda init zsh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a conda environment \"exp9\"\n",
    "\n",
    "```bash\n",
    "conda create -n exp9 python=3.9\n",
    "```\n",
    "\n",
    "Enter environment\n",
    "```bash\n",
    "conda activate exp9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install SpaCy models\n",
    "\n",
    "```bash\n",
    "pip install -U pip setuptools wheel\n",
    "pip install -U spacy\n",
    "python -m spacy download zh_core_web_sm\n",
    "python -m spacy download en_core_web_sm\n",
    "python -m spacy download fr_core_news_sm\n",
    "python -m spacy download de_core_news_sm\n",
    "python -m spacy download ja_core_news_sm\n",
    "python -m spacy download lt_core_news_sm\n",
    "python -m spacy download ru_core_news_sm\n",
    "python -m spacy download es_core_news_sm\n",
    "python -m spacy download uk_core_news_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup [wandb](https://docs.wandb.ai/guides/integrations/huggingface)\n",
    "\n",
    "\n",
    "1. sign up for an account in [wandb](https://wandb.ai/)\n",
    "2. create a `wandb` folder in the root of this repository\n",
    "3. set TMPDIR to the path of `wandb` folder\n",
    "3. login in local setting `wandb login` and follow the instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pre-training:\n",
    "\n",
    "```bash\n",
    "python3 code/generate_train_csv.py \\\n",
    "-i datasets/lcquad2/train.json \\\n",
    "-o datasets/lcquad2/train.csv \\\n",
    "-t lcquad2 \\\n",
    "--linguistic_context\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fine-tuning:\n",
    "\n",
    "```bash\n",
    "python3 code/generate_train_csv.py \\\n",
    "-i datasets/qald9plus/wikidata/qald_9_plus_train_wikidata.json \\\n",
    "-o datasets/qald9plus/wikidata/qald_9_plus_train_wikidata.csv \\\n",
    "-t qald \\\n",
    "-kg Wikidata \\\n",
    "-l all \\\n",
    "--linguistic_context\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train on LC-QuAD 2.0\n",
    "\n",
    "Since pre-training and fine-tuning commands are based on the same script `train_ds.sh`, in order to save time and avoid errors, we directly provide the code in the configured bash script. You can run the following command in your terminal.\n",
    "\n",
    "```bash\n",
    "deepspeed --include=localhost:0 --master_port 60000 code/train_new.py \\\n",
    "    --deepspeed deepspeed/ds_config_zero3.json \\\n",
    "    --model_name_or_path google/mt5-xl \\\n",
    "    --do_train \\\n",
    "    --train_file datasets/lcquad2/train.csv \\\n",
    "    --output_dir fine-tuned_models/exp9-pretrain \\\n",
    "    --num_train_epochs 32 \\\n",
    "    --per_device_train_batch_size=16 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --save_steps 6000 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --report_to wandb \\\n",
    "    --run_name exp9-pretrain \\\n",
    "    --tf32 1 \\\n",
    "    --fp16 0 \\\n",
    "    --gradient_checkpointing 1 \\\n",
    "    --gradient_accumulation_steps 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune on QALD-9-Plus\n",
    "\n",
    "```bash\n",
    "deepspeed --include=localhost:0 --master_port 60000 code/train_new.py \\\n",
    "    --deepspeed deepspeed/ds_config_zero3.json \\\n",
    "    --model_name_or_path fine-tuned_models/exp9-pretrain \\\n",
    "    --do_train \\\n",
    "    --train_file datasets/qald9plus/wikidata/qald_9_plus_train_wikidata.csv \\\n",
    "    --output_dir fine-tuned_models/exp9-fine-tune \\\n",
    "    --num_train_epochs 15 \\\n",
    "    --per_device_train_batch_size=16 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --save_steps 3000 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --report_to wandb \\\n",
    "    --run_name exp9-fine-tune \\\n",
    "    --tf32 1 \\\n",
    "    --fp16 0 \\\n",
    "    --gradient_checkpointing 1 \\\n",
    "    --gradient_accumulation_steps 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with GERBIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `eval.sh` to generate prediction files in QALD format and evaluate them with GERBIL.\n",
    "`eval.sh` is configured. \n",
    "\n",
    "```bash\n",
    "./eval.sh\n",
    "```\n",
    "\n",
    "Prediction files are stored in `pred_files/exp9-fine-tune`.\n",
    "The script uploads them to GERBIL along with the reference test file\n",
    "and waits for 5 minutes for the results.\n",
    "If the GERBIL experiment terminates, the results are stored in `pred_files/exp9-fine-tune/result.csv`, else, the experiment id is stored in this file. You can use the following commands to generate a csv files for results:\n",
    "\n",
    "```bash\n",
    "python3 code/gerbil_eval.py --experiment_id [experiment_id] --pred_path pred_files/exp9-fine-tune\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

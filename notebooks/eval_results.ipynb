{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/upb/users/m/mengshim/profiles/unix/cs/miniconda3/envs/mengshi/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Results\n",
    "\n",
    "After fine-tuning the models, we need to evaluate their performance. We use [GERBIL](https://gerbil-qa.aksw.org/gerbil/config) to calculate the F1 score of each model and language individually. We convert the questions in the test dataset to SPARQL queries, send them to [Wikidata Query Service](https://query.wikidata.org/) to get answers, and build a dataset in QALD format. Then, we upload this file to GERBIL and evaluate it.\n",
    "\n",
    "We conduct ablation studies using different models with different tokenizers. We fine-tune the models on the [QALD-9-plus](https://github.com/KGQA/QALD_9_plus) training dataset, a multilingual dataset that extends QALD-9 with more questions in nine languages and covers both DBpedia and Wikidata as knowledge graphs, and evaluate them on the test dataset. Since there are only european languages in the QALD-9-plus dataset, we also add Chinese and Japanese translations of questions to expand the coverage of languages for KGQA research and applications and enable multilingual KGQA models to learn from more diverse and rich data.\n",
    "\n",
    "Note that unless otherwise stated, all answers is limited to 50 results to avoid excessive file size. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "The first experiment aims to leverage a multilingual text-to-text transformer model called [mT5-base](https://huggingface.co/google/mt5-base) to answer natural language questions over linked data. \n",
    "The model is previously  pre-trained on a large-scale dataset called [LC-QuAD](https://github.com/AskNowQA/LC-QuAD) that contains over 5000 questions and their corresponding SPARQL queries. \n",
    "We also filter out entities and relations in LC-QuAD dataset and add them to mt5 tokenizer to improve tokenizing knowledge graph entities. This new tokenizer is trained on LC-QuAD training dataset. \n",
    "\n",
    "We fine-tuned a pre-trained language model on different datasets that contain varying numbers of languages. We experimented with four settings: one-shot, few-shot, no-en, and all languages. \n",
    "- In the one-shot setting, we fine-tuned the model on only English questions. \n",
    "- In the few-shot setting, we fine-tuned the model on a small amount of languages. \n",
    "- In the no-en setting, we exclude English questions from dataset while including all other languages.\n",
    "- In the all languages setting, we fine-tuned the model on all the available languages.\n",
    "\n",
    "The experiment runs for 300 epochs before evaluation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we show you the results of the mT5 tokenizer on tokenizing SPARQL query. \n",
    "Note that these SPARQL queries are preprocessed to simplify tokenization and reduce syntax errors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take three example SPARQL queries. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query1: \n",
    "- Which instruments does Cat Stevens play?\n",
    "- `SELECT DISTINCT var_uri WHERE bra_open wd_Q154216 wdt_P1303 var_uri sep_dot bra_close`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"SELECT DISTINCT var_uri WHERE bra_open wd_Q154216 wdt_P1303 var_uri sep_dot bra_close\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is horse racing a sport?\n",
    "- `ASK WHERE bra_open wd_Q187916 wdt_P279* wd_Q349 sep_dot bra_close`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"ASK WHERE bra_open wd_Q187916 wdt_P279* wd_Q349 sep_dot bra_close\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which states border Illinois?\n",
    "- `SELECT DISTINCT var_uri WHERE bra_open wd_Q1204 wdt_P47 var_uri sep_dot bra_close`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"SELECT DISTINCT var_uri WHERE bra_open wd_Q1204 wdt_P47 var_uri sep_dot bra_close\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we show how mT5 tokenizer tokenizes SPARQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/upb/users/m/mengshim/profiles/unix/cs/miniconda3/envs/mengshi/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mt5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'SELECT', '▁D', 'ISTI', 'NCT', '▁var', '_', 'uri', '▁W', 'HERE', '▁bra', '_', 'open', '▁w', 'd', '_', 'Q', '1542', '16', '▁w', 'd', 't', '_', 'P', '1303', '▁var', '_', 'uri', '▁sep', '_', 'dot', '▁bra', '_', 'close'], "
     ]
    }
   ],
   "source": [
    "tokens = mt5_tokenizer.tokenize(query1)\n",
    "print(tokens, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'ASK', '▁W', 'HERE', '▁bra', '_', 'open', '▁w', 'd', '_', 'Q', '1879', '16', '▁w', 'd', 't', '_', 'P', '279', '*', '▁w', 'd', '_', 'Q', '349', '▁sep', '_', 'dot', '▁bra', '_', 'close'], "
     ]
    }
   ],
   "source": [
    "tokens = mt5_tokenizer.tokenize(query2)\n",
    "print(tokens, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'SELECT', '▁D', 'ISTI', 'NCT', '▁var', '_', 'uri', '▁W', 'HERE', '▁bra', '_', 'open', '▁w', 'd', '_', 'Q', '1204', '▁w', 'd', 't', '_', 'P', '47', '▁var', '_', 'uri', '▁sep', '_', 'dot', '▁bra', '_', 'close'], "
     ]
    }
   ],
   "source": [
    "tokens = mt5_tokenizer.tokenize(query3)\n",
    "print(tokens, end=\", \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that entities and relations are tokenized as some single letters and numbers, therefore, the meaning of entities and relations is lost. \n",
    "We filter out entities and relations from LC-QuAD dataset to expand vocabulary of mT5 tokenizer. \n",
    "\n",
    "Now, we demonstrate the tokenization results of our new trained tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcquad_tokenizer = AutoTokenizer.from_pretrained(\"../lcquad_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'SELECT', '▁D', 'ISTI', 'NCT', '▁var', '_', 'uri', '▁W', 'HERE', '▁', 'bra_open', '▁', 'wd_Q154', '▁216', '▁', 'wdt_P1303', '▁var', '_', 'uri', '▁', 'sep_dot', '▁', 'bra_close'], "
     ]
    }
   ],
   "source": [
    "tokens = lcquad_tokenizer.tokenize(query1)\n",
    "print(tokens, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'ASK', '▁W', 'HERE', '▁', 'bra_open', '▁', 'wd_Q18', '▁7', '916', '▁', 'wdt_P279', '▁*', '▁', 'wd_Q349', '▁', 'sep_dot', '▁', 'bra_close'], "
     ]
    }
   ],
   "source": [
    "tokens = lcquad_tokenizer.tokenize(query2)\n",
    "print(tokens, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'SELECT', '▁D', 'ISTI', 'NCT', '▁var', '_', 'uri', '▁W', 'HERE', '▁', 'bra_open', '▁', 'wd_Q1204', '▁', 'wdt_P47', '▁var', '_', 'uri', '▁', 'sep_dot', '▁', 'bra_close'], "
     ]
    }
   ],
   "source": [
    "tokens = lcquad_tokenizer.tokenize(query3)\n",
    "print(tokens, end=\", \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, some entities and relations are tokenized correctly. \n",
    "Although many tokens from LC-QuAD are added to mT5 tokenizer, it does not contain entire wikidata entities and relations. Some entities and relations are still not tokenized correctly. \n",
    "It remains to see the tokenization result of SPARQL queries for smaller knowledge graphs when entities and relations are added into a tokenizer. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-shot\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first fine-tune with only English questions, which takes less time while fine-tuning. \n",
    "\n",
    "result: https://gerbil-qa.aksw.org/gerbil/experiment?id=202304030010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1 QALD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-shot ba (uploaded)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-shot be (uploaded)</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.3323</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>0.1632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-shot de (uploaded)</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-shot en (uploaded)</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.1748</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.1777</td>\n",
       "      <td>0.2891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-shot fr (uploaded)</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0-shot hy (uploaded)</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0-shot ja (uploaded)</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>0.1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0-shot lt (uploaded)</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0-shot ru (uploaded)</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.0846</td>\n",
       "      <td>0.1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0-shot uk (uploaded)</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0-shot zh (uploaded)</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0837</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.1517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Annotator  Micro F1  Micro Precision  Micro Recall  Macro F1  \\\n",
       "0   0-shot ba (uploaded)    0.0000           0.0000        0.0000    0.0441   \n",
       "1   0-shot be (uploaded)    0.0070           0.3323        0.0036    0.0923   \n",
       "2   0-shot de (uploaded)    0.0055           0.1401        0.0028    0.0819   \n",
       "3   0-shot en (uploaded)    0.0094           0.2216        0.0048    0.1748   \n",
       "4   0-shot fr (uploaded)    0.0067           0.7955        0.0034    0.0776   \n",
       "5   0-shot hy (uploaded)    0.0031           0.2526        0.0015    0.0411   \n",
       "6   0-shot ja (uploaded)    0.0004           0.0216        0.0002    0.0700   \n",
       "7   0-shot lt (uploaded)    0.0066           0.2178        0.0034    0.0776   \n",
       "8   0-shot ru (uploaded)    0.0039           0.1148        0.0020    0.0793   \n",
       "9   0-shot uk (uploaded)    0.0081           0.2075        0.0041    0.0666   \n",
       "10  0-shot zh (uploaded)    0.0044           0.3151        0.0022    0.0837   \n",
       "\n",
       "    Macro Precision  Macro Recall  Macro F1 QALD  \n",
       "0            0.0441        0.0441         0.0844  \n",
       "1            0.0953        0.0907         0.1632  \n",
       "2            0.0821        0.0822         0.1475  \n",
       "3            0.1785        0.1777         0.2891  \n",
       "4            0.0806        0.0760         0.1409  \n",
       "5            0.0438        0.0399         0.0767  \n",
       "6            0.0701        0.0699         0.1293  \n",
       "7            0.0806        0.0760         0.1402  \n",
       "8            0.0817        0.0846         0.1510  \n",
       "9            0.0746        0.0639         0.1175  \n",
       "10           0.0859        0.0829         0.1517  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../pred_files/pretrain_lcqald/1/results.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "- English has the best performance across this experiment\n",
    "- bad performance on all other languages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-shot "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experiment with four languages of questions: en, de, zh, and ru.\n",
    "\n",
    "result: https://gerbil-qa.aksw.org/gerbil/experiment?id=202304250003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1 QALD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrain_lcquad_few-shot_ba (uploaded)</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.3316</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.1607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretrain_lcquad_few-shot_be (uploaded)</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.1839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pretrain_lcquad_few-shot_de (uploaded)</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.1281</td>\n",
       "      <td>0.2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretrain_lcquad_few-shot_en (uploaded)</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretrain_lcquad_few-shot_fr (uploaded)</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pretrain_lcquad_few-shot_hy (uploaded)</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.0901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pretrain_lcquad_few-shot_ja (uploaded)</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.1944</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>0.1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pretrain_lcquad_few-shot_lt (uploaded)</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pretrain_lcquad_few-shot_ru (uploaded)</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.2387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pretrain_lcquad_few-shot_uk (uploaded)</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.1532</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pretrain_lcquad_few-shot_zh (uploaded)</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.2244</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1222</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Annotator  Micro F1  Micro Precision  \\\n",
       "0   pretrain_lcquad_few-shot_ba (uploaded)    0.0040           0.3316   \n",
       "1   pretrain_lcquad_few-shot_be (uploaded)    0.0086           0.1741   \n",
       "2   pretrain_lcquad_few-shot_de (uploaded)    0.0088           0.1932   \n",
       "3   pretrain_lcquad_few-shot_en (uploaded)    0.0089           0.2220   \n",
       "4   pretrain_lcquad_few-shot_fr (uploaded)    0.0067           0.5866   \n",
       "5   pretrain_lcquad_few-shot_hy (uploaded)    0.0034           0.3354   \n",
       "6   pretrain_lcquad_few-shot_ja (uploaded)    0.0088           0.1944   \n",
       "7   pretrain_lcquad_few-shot_lt (uploaded)    0.0091           0.1929   \n",
       "8   pretrain_lcquad_few-shot_ru (uploaded)    0.0094           0.2104   \n",
       "9   pretrain_lcquad_few-shot_uk (uploaded)    0.0086           0.1532   \n",
       "10  pretrain_lcquad_few-shot_zh (uploaded)    0.0088           0.2244   \n",
       "\n",
       "    Micro Recall  Macro F1  Macro Precision  Macro Recall  Macro F1 QALD  \n",
       "0         0.0020    0.0897           0.0938        0.0887         0.1607  \n",
       "1         0.0044    0.1072           0.1137        0.1055         0.1839  \n",
       "2         0.0045    0.1299           0.1363        0.1281         0.2173  \n",
       "3         0.0045    0.1518           0.1582        0.1500         0.2502  \n",
       "4         0.0034    0.0775           0.0804        0.0761         0.1412  \n",
       "5         0.0017    0.0484           0.0510        0.0472         0.0901  \n",
       "6         0.0045    0.1146           0.1213        0.1129         0.1961  \n",
       "7         0.0047    0.0971           0.1097        0.0971         0.1729  \n",
       "8         0.0048    0.1416           0.1468        0.1425         0.2387  \n",
       "9         0.0044    0.1150           0.1215        0.1132         0.1944  \n",
       "10        0.0045    0.1222           0.1363        0.1183         0.2036  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../pred_files/pretrain_lcqald/4/results.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "- languages in training dataset performs better than other languages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all languages (11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all languages setting, we include en, de, zh, ja, ru, fr, hy, ba, be, uk, lt. \n",
    "es is not included since our Spanish translation of questions is merged later than this experiment.\n",
    "\n",
    "result: https://gerbil-qa.aksw.org/gerbil/experiment?id=202304250002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1 QALD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrain_lcquad_ba (uploaded)</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.1256</td>\n",
       "      <td>0.2157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretrain_lcquad_be (uploaded)</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.1293</td>\n",
       "      <td>0.2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pretrain_lcquad_de (uploaded)</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretrain_lcquad_en (uploaded)</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.1796</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretrain_lcquad_fr (uploaded)</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pretrain_lcquad_hy (uploaded)</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.4320</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pretrain_lcquad_ja (uploaded)</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pretrain_lcquad_lt (uploaded)</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.2145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pretrain_lcquad_ru (uploaded)</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.1427</td>\n",
       "      <td>0.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pretrain_lcquad_uk (uploaded)</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.1501</td>\n",
       "      <td>0.2469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pretrain_lcquad_zh (uploaded)</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Annotator  Micro F1  Micro Precision  Micro Recall  \\\n",
       "0   pretrain_lcquad_ba (uploaded)    0.0044           0.2438        0.0022   \n",
       "1   pretrain_lcquad_be (uploaded)    0.0103           0.2195        0.0053   \n",
       "2   pretrain_lcquad_de (uploaded)    0.0091           0.2117        0.0047   \n",
       "3   pretrain_lcquad_en (uploaded)    0.0088           0.1796        0.0045   \n",
       "4   pretrain_lcquad_fr (uploaded)    0.0067           0.7000        0.0034   \n",
       "5   pretrain_lcquad_hy (uploaded)    0.0035           0.4320        0.0017   \n",
       "6   pretrain_lcquad_ja (uploaded)    0.0091           0.2362        0.0047   \n",
       "7   pretrain_lcquad_lt (uploaded)    0.0102           0.2414        0.0052   \n",
       "8   pretrain_lcquad_ru (uploaded)    0.0089           0.2319        0.0045   \n",
       "9   pretrain_lcquad_uk (uploaded)    0.0089           0.1759        0.0046   \n",
       "10  pretrain_lcquad_zh (uploaded)    0.0088           0.2112        0.0045   \n",
       "\n",
       "    Macro F1  Macro Precision  Macro Recall  Macro F1 QALD  \n",
       "0     0.1266           0.1307        0.1256         0.2157  \n",
       "1     0.1316           0.1394        0.1293         0.2178  \n",
       "2     0.1666           0.1731        0.1648         0.2700  \n",
       "3     0.1373           0.1510        0.1355         0.2275  \n",
       "4     0.0775           0.0804        0.0761         0.1412  \n",
       "5     0.0631           0.0657        0.0619         0.1165  \n",
       "6     0.1403           0.1460        0.1402         0.2338  \n",
       "7     0.1260           0.1319        0.1248         0.2145  \n",
       "8     0.1446           0.1582        0.1427         0.2376  \n",
       "9     0.1519           0.1584        0.1501         0.2469  \n",
       "10    0.1226           0.1290        0.1209         0.2054  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../pred_files/pretrain_lcqald/11/results.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "- `de` has the best performance\n",
    "- bad performance on `fr` and `hy`\n",
    "- no obvious difference between other languages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no-en"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude English question to test the influence on English performance. \n",
    "\n",
    "result: https://gerbil-qa.aksw.org/gerbil/experiment?id=202304250002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1 QALD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrain_lcquad_no-en_ba (uploaded)</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.2334</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.1191</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.2056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretrain_lcquad_no-en_be (uploaded)</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.1972</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pretrain_lcquad_no-en_de (uploaded)</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretrain_lcquad_no-en_en (uploaded)</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.2290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretrain_lcquad_no-en_fr (uploaded)</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.5412</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pretrain_lcquad_no-en_hy (uploaded)</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pretrain_lcquad_no-en_ja (uploaded)</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pretrain_lcquad_no-en_lt (uploaded)</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.1165</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pretrain_lcquad_no-en_ru (uploaded)</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.2082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pretrain_lcquad_no-en_uk (uploaded)</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.2067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pretrain_lcquad_no-en_zh (uploaded)</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.1141</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.1842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Annotator  Micro F1  Micro Precision  \\\n",
       "0   pretrain_lcquad_no-en_ba (uploaded)    0.0043           0.2334   \n",
       "1   pretrain_lcquad_no-en_be (uploaded)    0.0088           0.1972   \n",
       "2   pretrain_lcquad_no-en_de (uploaded)    0.0088           0.1898   \n",
       "3   pretrain_lcquad_no-en_en (uploaded)    0.0087           0.1673   \n",
       "4   pretrain_lcquad_no-en_fr (uploaded)    0.0067           0.5412   \n",
       "5   pretrain_lcquad_no-en_hy (uploaded)    0.0034           0.3776   \n",
       "6   pretrain_lcquad_no-en_ja (uploaded)    0.0089           0.2129   \n",
       "7   pretrain_lcquad_no-en_lt (uploaded)    0.0092           0.1929   \n",
       "8   pretrain_lcquad_no-en_ru (uploaded)    0.0087           0.2315   \n",
       "9   pretrain_lcquad_no-en_uk (uploaded)    0.0086           0.1823   \n",
       "10  pretrain_lcquad_no-en_zh (uploaded)    0.0086           0.2145   \n",
       "\n",
       "    Micro Recall  Macro F1  Macro Precision  Macro Recall  Macro F1 QALD  \n",
       "0         0.0021    0.1191           0.1232        0.1181         0.2056  \n",
       "1         0.0045    0.1226           0.1291        0.1207         0.2070  \n",
       "2         0.0045    0.1298           0.1363        0.1280         0.2173  \n",
       "3         0.0045    0.1371           0.1435        0.1353         0.2290  \n",
       "4         0.0034    0.0775           0.0804        0.0761         0.1411  \n",
       "5         0.0017    0.0631           0.0657        0.0619         0.1165  \n",
       "6         0.0046    0.1444           0.1510        0.1426         0.2367  \n",
       "7         0.0047    0.1165           0.1228        0.1148         0.1980  \n",
       "8         0.0044    0.1224           0.1288        0.1206         0.2082  \n",
       "9         0.0044    0.1224           0.1288        0.1206         0.2067  \n",
       "10        0.0044    0.1077           0.1141        0.1059         0.1842  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../pred_files/pretrain_lcqald/no_en/results.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "- almost all performance is worse than with English questions\n",
    "- `ja` is improved slightly\n",
    "- no significant result w/o English questions for `en`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second experiment, we try google/mt5-base model with mT5 tokenizer without any pretraining on LC-QuAD dataset to observe whether pretraining on LC-QuAD and adding tokens to tokenizer improve the performance. \n",
    "\n",
    "Also, the experiment runs for 300 epochs before evaluation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all languages (12)\n",
    "\n",
    "en, de, zh, ja, ru, fr, hy, ba, be, uk, lt, es\n",
    "\n",
    "https://gerbil-qa.aksw.org/gerbil/experiment?id=202304080000\n",
    "\n",
    "| language | Micro-F1 | Micro-Precision | Micro-Recall | Macro-F1 | Macro-Precision | Macro-Recall | Macro-F1 QALD |\n",
    "|----------|----------|-----------------|--------------|----------|-----------------|--------------|---------------|\n",
    "| en       | 0.0099   | 0.1429          | 0.0051       | 0.1914   | 0.2134          | 0.1884       | 0.2585        |\n",
    "| zh       | 0.0105   | 0.1482          | 0.0055       | 0.2069   | 0.2198          | 0.2037       | 0.2619        |\n",
    "| de       | 0.0099   | 0.1477          | 0.0051       | 0.1962   | 0.2137          | 0.192        | 0.2634        |\n",
    "| fr       | 0.0068   | 0.5354          | 0.0034       | 0.0775   | 0.0804          | 0.0761       | 0.1408        |\n",
    "| ja       | 0.0104   | 0.1583          | 0.0054       | 0.1966   | 0.2052          | 0.1945       | 0.2625        |\n",
    "| ru       | 0.0104   | 0.1369          | 0.0054       | 0.1775   | 0.1907          | 0.1742       | 0.2393        |\n",
    "| uk       | 0.0099   | 0.1451          | 0.0051       | 0.2131   | 0.2244          | 0.2103       | 0.2941        |\n",
    "| hy       | 0.0034   | 0.1957          | 0.0017       | 0.0558   | 0.0584          | 0.0546       | 0.103         |\n",
    "| ba       | 0.0056   | 0.1589          | 0.0029       | 0.1571   | 0.1628          | 0.1557       | 0.2457        |\n",
    "| be       | 0.0098   | 0.1442          | 0.0051       | 0.1986   | 0.2171          | 0.1956       | 0.2704        |\n",
    "| lt       | 0.0104   | 0.1307          | 0.0054       | 0.19     | 0.2089          | 0.1854       | 0.2641        |\n",
    "\n",
    "- without limit on number of answer: https://gerbil-qa.aksw.org/gerbil/experiment?id=202304080001\n",
    "\n",
    "| language | Micro-F1 | Micro-Precision | Micro-Recall | Macro-F1 | Macro-Precision | Macro-Recall | Macro-F1 QALD |\n",
    "|----------|----------|-----------------|--------------|----------|-----------------|--------------|---------------|\n",
    "| en       | 0.0072   | 0.0066          | 0.0081       | 0.2093   | 0.228           | 0.2083       | 0.2749        |\n",
    "| zh       | 0.0063   | 0.0051          | 0.0084       | 0.2248   | 0.2343          | 0.2235       | 0.2777        |\n",
    "| de       | 0.0079   | 0.0077          | 0.008        | 0.2139   | 0.228           | 0.2115       | 0.2828        |\n",
    "| fr       | 0.0111   | 0.4137          | 0.0056       | 0.088    | 0.0877          | 0.0882       | 0.1613        |\n",
    "| ja       | 0.0069   | 0.0059          | 0.0083       | 0.2144   | 0.2198          | 0.214        | 0.2761        |\n",
    "| ru       | 0.007    | 0.006           | 0.0083       | 0.1953   | 0.2051          | 0.1938       | 0.2553        |\n",
    "| uk       | 0.0071   | 0.0063          | 0.0081       | 0.2309   | 0.2388          | 0.2302       | 0.313         |\n",
    "| hy       | 0.006    | 0.0144          | 0.0038       | 0.066    | 0.0659          | 0.0662       | 0.1235        |\n",
    "| ba       | 0.0047   | 0.0116          | 0.003        | 0.1573   | 0.1625          | 0.1563       | 0.2457        |\n",
    "| be       | 0.0071   | 0.0064          | 0.008        | 0.2164   | 0.2316          | 0.2151       | 0.2852        |\n",
    "| lt       | 0.0076   | 0.0071          | 0.0083       | 0.1931   | 0.2087          | 0.1902       | 0.265         |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-shot\n",
    "\n",
    "en, de, zh, ru\n",
    "\n",
    "https://gerbil-qa.aksw.org/gerbil/experiment?id=202304040000\n",
    "\n",
    "| language | Micro-F1 | Micro-Precision | Micro-Recall | Macro-F1 | Macro-Precision | Macro-Recall | Macro-F1 QALD |\n",
    "|----------|----------|-----------------|--------------|----------|-----------------|--------------|---------------|\n",
    "| en       | 0.0096   | 0.134           | 0.005        | 0.1915   | 0.203           | 0.1886       | 0.2596        |\n",
    "| zh       | 0.0096   | 0.1518          | 0.005        | 0.1811   | 0.1912          | 0.1808       | 0.2512        |\n",
    "| de       | 0.0098   | 0.1708          | 0.0051       | 0.2062   | 0.2177          | 0.2033       | 0.2821        |\n",
    "| fr       | 0.0068   | 0.5408          | 0.0034       | 0.0775   | 0.0804          | 0.0761       | 0.1409        |\n",
    "| ja       | 0.0082   | 0.1904          | 0.0042       | 0.143    | 0.1526          | 0.1396       | 0.2144        |\n",
    "| ru       | 0.0095   | 0.1313          | 0.0049       | 0.1548   | 0.1664          | 0.1518       | 0.2236        |\n",
    "| uk       | 0.0094   | 0.1421          | 0.0048       | 0.1664   | 0.1766          | 0.1661       | 0.2391        |\n",
    "| hy       | 0.0037   | 0.3118          | 0.0019       | 0.0579   | 0.0597          | 0.0595       | 0.1119        |\n",
    "| ba       | 0.0045   | 0.2023          | 0.0023       | 0.1267   | 0.1342          | 0.1256       | 0.2116        |\n",
    "| be       | 0.0096   | 0.1835          | 0.0049       | 0.1489   | 0.1593          | 0.1514       | 0.227         |\n",
    "| lt       | 0.0088   | 0.1956          | 0.0045       | 0.134    | 0.1428          | 0.1311       | 0.211         |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-shot\n",
    "\n",
    "en\n",
    "\n",
    "https://gerbil-qa.aksw.org/gerbil/experiment?id=202304050000\n",
    "\n",
    "| language | Micro-F1 | Micro-Precision | Micro-Recall | Macro-F1 | Macro-Precision | Macro-Recall | Macro-F1 QALD |\n",
    "|----------|----------|-----------------|--------------|----------|-----------------|--------------|---------------|\n",
    "| en       | 0.0098   | 0.2193          | 0.005        | 0.2185   | 0.2324          | 0.2143       | 0.3207        |\n",
    "| zh       | 0.0031   | 0.0654          | 0.0016       | 0.0558   | 0.0584          | 0.0546       | 0.1007        |\n",
    "| de       | 0.0088   | 0.1519          | 0.0046       | 0.1152   | 0.1289          | 0.1112       | 0.189         |\n",
    "| fr       | 0.0064   | 0.6061          | 0.0032       | 0.065    | 0.0732          | 0.0625       | 0.1175        |\n",
    "| ja       | 0.0032   | 0.0741          | 0.0016       | 0.0554   | 0.0657          | 0.0521       | 0.0963        |\n",
    "| ru       | 0.0049   | 0.0936          | 0.0025       | 0.1007   | 0.1086          | 0.1001       | 0.1724        |\n",
    "| uk       | 0.0046   | 0.0941          | 0.0023       | 0.0567   | 0.0645          | 0.0621       | 0.1139        |\n",
    "| hy       | 0.0031   | 0.8727          | 0.0015       | 0.0485   | 0.0512          | 0.0473       | 0.0902        |\n",
    "| ba       | 0.0001   | 0.0039          | 0            | 0.0515   | 0.0515          | 0.0515       | 0.0971        |\n",
    "| be       | 0.0046   | 0.1299          | 0.0023       | 0.086    | 0.0934          | 0.0854       | 0.1524        |\n",
    "| lt       | 0.0063   | 0.1477          | 0.0032       | 0.0503   | 0.0585          | 0.048        | 0.093         |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3\n",
    "\n",
    "Config:\n",
    "- model: mt5-base\n",
    "- tokenizer: mt5 tokenizer with added tokens from lcquad\n",
    "- epochs: 300"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-shot\n",
    "\n",
    "en\n",
    "\n",
    "https://gerbil-qa.aksw.org/gerbil/experiment?id=202304050004\n",
    "\n",
    "| language | Micro-F1 | Micro-Precision | Micro-Recall | Macro-F1 | Macro-Precision | Macro-Recall | Macro-F1 QALD |\n",
    "|----------|----------|-----------------|--------------|----------|-----------------|--------------|---------------|\n",
    "| en       | 0.0091   | 0.2416          | 0.0046       | 0.1666   | 0.1726          | 0.1662       | 0.2718        |\n",
    "| zh       | 0.0004   | 0.0261          | 0.0002       | 0.0662   | 0.0662          | 0.0662       | 0.1216        |\n",
    "| de       | 0.0082   | 0.1813          | 0.0042       | 0.1005   | 0.1072          | 0.0986       | 0.171         |\n",
    "| fr       | 0.0067   | 0.3608          | 0.0034       | 0.0776   | 0.0806          | 0.076        | 0.1407        |\n",
    "| ja       | 0.0038   | 0.169           | 0.0019       | 0.0886   | 0.0956          | 0.0879       | 0.1569        |\n",
    "| ru       | 0.0077   | 0.2111          | 0.0039       | 0.1122   | 0.1236          | 0.1088       | 0.1882        |\n",
    "| uk       | 0.0085   | 0.1648          | 0.0044       | 0.1034   | 0.1216          | 0.1003       | 0.1749        |\n",
    "| hy       | 0.0034   | 0               | 0            | 0.0368   | 0.0368          | 0.0368       | 0.0707        |\n",
    "| ba       | 0.0032   | 0.1932          | 0.0016       | 0.0585   | 0.0588          | 0.0581       | 0.1089        |\n",
    "| be       | 0.0086   | 0.1854          | 0.0044       | 0.1107   | 0.1213          | 0.1091       | 0.1892        |\n",
    "| lt       | 0.0071   | 0.1728          | 0.0036       | 0.0793   | 0.0861          | 0.0771       | 0.1406        |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-shot\n",
    "\n",
    "en, de, zh, ru\n",
    "\n",
    "https://gerbil-qa.aksw.org/gerbil/experiment?id=202304050001\n",
    "\n",
    "| language | Micro-F1 | Micro-Precision | Micro-Recall | Macro-F1 | Macro-Precision | Macro-Recall | Macro-F1 QALD |\n",
    "|----------|----------|-----------------|--------------|----------|-----------------|--------------|---------------|\n",
    "| en       | 0.0089   | 0.1725          | 0.0046       | 0.1591   | 0.1653          | 0.1642       | 0.2578        |\n",
    "| zh       | 0.0087   | 0.2208          | 0.0044       | 0.115    | 0.121           | 0.1201       | 0.2016        |\n",
    "| de       | 0.0089   | 0.1736          | 0.0046       | 0.1513   | 0.1578          | 0.1496       | 0.2406        |\n",
    "| fr       | 0.0067   | 0.7955          | 0.0034       | 0.0775   | 0.0804          | 0.0761       | 0.1411        |\n",
    "| ja       | 0.0086   | 0.2036          | 0.0044       | 0.1218   | 0.1281          | 0.1201       | 0.2041        |\n",
    "| ru       | 0.0087   | 0.2094          | 0.0044       | 0.122    | 0.1356          | 0.1202       | 0.2029        |\n",
    "| uk       | 0.0087   | 0.1893          | 0.0044       | 0.1291   | 0.1356          | 0.1274       | 0.2135        |\n",
    "| hy       | 0.0034   | 0.53            | 0.0017       | 0.0558   | 0.0584          | 0.0546       | 0.1034        |\n",
    "| ba       | 0.0039   | 0.202           | 0.002        | 0.0897   | 0.0938          | 0.0887       | 0.1591        |\n",
    "| be       | 0.0083   | 0.1421          | 0.0043       | 0.1071   | 0.1135          | 0.1054       | 0.1819        |\n",
    "| lt       | 0.0086   | 0.1568          | 0.0044       | 0.0925   | 0.0992          | 0.0908       | 0.1595        |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4\n",
    "\n",
    "Config:\n",
    "- model: mt5-base\n",
    "- tokenizer: mt5 tokenizer\n",
    "- epochs: 300\n",
    "- training data: natural language questions with POS tags, dependency relation, and dependency level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all languages (11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en, de, zh, ja, ru, fr, ba, be, uk, lt, es\n",
    "\n",
    "There is no spacy model for Armenian, hence, Armenian is excluded.\n",
    "\n",
    "https://gerbil-qa.aksw.org/gerbil/experiment?id=202304170000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1 QALD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linguistic_mt5_11_ba (uploaded)</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.1858</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.1682</td>\n",
       "      <td>0.1571</td>\n",
       "      <td>0.2498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linguistic_mt5_11_be (uploaded)</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linguistic_mt5_11_de (uploaded)</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.2253</td>\n",
       "      <td>0.2392</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linguistic_mt5_11_en (uploaded)</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.2543</td>\n",
       "      <td>0.2433</td>\n",
       "      <td>0.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linguistic_mt5_11_es (uploaded)</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.3161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linguistic_mt5_11_fr (uploaded)</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linguistic_mt5_11_ja (uploaded)</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.2832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>linguistic_mt5_11_lt (uploaded)</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.2179</td>\n",
       "      <td>0.2312</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.2988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linguistic_mt5_11_ru (uploaded)</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>linguistic_mt5_11_uk (uploaded)</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.2537</td>\n",
       "      <td>0.2396</td>\n",
       "      <td>0.3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>linguistic_mt5_11_zh (uploaded)</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>0.2097</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.2651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Annotator  Micro F1  Micro Precision  Micro Recall  \\\n",
       "0   linguistic_mt5_11_ba (uploaded)    0.0066           0.1858        0.0034   \n",
       "1   linguistic_mt5_11_be (uploaded)    0.0101           0.1567        0.0052   \n",
       "2   linguistic_mt5_11_de (uploaded)    0.0101           0.1397        0.0053   \n",
       "3   linguistic_mt5_11_en (uploaded)    0.0103           0.1515        0.0053   \n",
       "4   linguistic_mt5_11_es (uploaded)    0.0100           0.1450        0.0052   \n",
       "5   linguistic_mt5_11_fr (uploaded)    0.0067           0.4380        0.0034   \n",
       "6   linguistic_mt5_11_ja (uploaded)    0.0099           0.1660        0.0051   \n",
       "7   linguistic_mt5_11_lt (uploaded)    0.0095           0.1350        0.0049   \n",
       "8   linguistic_mt5_11_ru (uploaded)    0.0099           0.1348        0.0052   \n",
       "9   linguistic_mt5_11_uk (uploaded)    0.0101           0.1349        0.0052   \n",
       "10  linguistic_mt5_11_zh (uploaded)    0.0099           0.1572        0.0051   \n",
       "\n",
       "    Macro F1  Macro Precision  Macro Recall  Macro F1 QALD  \n",
       "0     0.1590           0.1682        0.1571         0.2498  \n",
       "1     0.2133           0.2245        0.2114         0.2851  \n",
       "2     0.2253           0.2392        0.2212         0.2939  \n",
       "3     0.2432           0.2543        0.2433         0.3200  \n",
       "4     0.2353           0.2467        0.2335         0.3161  \n",
       "5     0.0849           0.0878        0.0835         0.1531  \n",
       "6     0.2008           0.2098        0.2047         0.2832  \n",
       "7     0.2179           0.2312        0.2138         0.2988  \n",
       "8     0.2130           0.2243        0.2102         0.2775  \n",
       "9     0.2424           0.2537        0.2396         0.3019  \n",
       "10    0.1961           0.2097        0.1930         0.2651  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../pred_files/mt5_linguistic/11_linguistic_mt5/results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mengshi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

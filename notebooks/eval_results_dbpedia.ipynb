{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutation results for DBpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_macro_f1(languages: set, f1_scores: dict, x_distance, figsize):\n",
    "    x = np.arange(len(languages)) * x_distance  # the label locations\n",
    "    width = 0.4  # the width of the bars\n",
    "    multiplier = 0\n",
    "\n",
    "    fig, ax = plt.subplots(layout='constrained', figsize=figsize)\n",
    "\n",
    "    for attribute, measurement in f1_scores.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        ax.bar_label(rects, fmt='%.2f')\n",
    "        multiplier += 1\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('F1 Score')\n",
    "    ax.set_title('F1 Scores by languages')\n",
    "    ax.set_xticks(x + width*(len(f1_scores)-1)/2, languages)\n",
    "    ax.legend(loc='upper left', ncols=3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_lang_set(results):\n",
    "    languages_list = [set(result[\"Language\"].tolist())\n",
    "                      for result in results.values()]\n",
    "    return set().union(*languages_list)\n",
    "\n",
    "\n",
    "def get_f1_scores(results, languages):\n",
    "    f1_scores = {}\n",
    "    for name, result_df in results.items():\n",
    "        scores = list()\n",
    "        for lang in languages:\n",
    "            try:\n",
    "                macro_f1 = result_df.loc[result_df[\"Language\"]\n",
    "                                         == lang, \"Macro F1\"].iloc[0]\n",
    "            except:\n",
    "                macro_f1 = 0\n",
    "            scores.append(macro_f1)\n",
    "        f1_scores[name] = scores\n",
    "    return f1_scores\n",
    "\n",
    "def plot(results, x_distance=1, figsize=(8, 8)):\n",
    "    languages = get_lang_set(results)\n",
    "    f1_scores = get_f1_scores(results, languages)\n",
    "    plot_macro_f1(languages, f1_scores, x_distance, figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we only fine-tuned mT5-base model on qald-9-plus with DBpedia SPARQLs for 100 epochs as our baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1 QALD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ba</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.2901</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>0.2997</td>\n",
       "      <td>0.4436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.3255</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>0.3652</td>\n",
       "      <td>0.3813</td>\n",
       "      <td>0.5045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.3727</td>\n",
       "      <td>0.3709</td>\n",
       "      <td>0.3887</td>\n",
       "      <td>0.5183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.4864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.2553</td>\n",
       "      <td>0.4036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lt</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.3435</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.5007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ru</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>0.3697</td>\n",
       "      <td>0.5043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>uk</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.3748</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>0.3935</td>\n",
       "      <td>0.5244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language  Micro F1  Micro Precision  Micro Recall  Macro F1  \\\n",
       "0       ba    0.0633           0.1472        0.0404    0.2901   \n",
       "1       be    0.1366           0.3255        0.0864    0.3670   \n",
       "2       de    0.0439           0.0288        0.0922    0.3727   \n",
       "3       en    0.0313           0.0204        0.0680    0.3352   \n",
       "4       fr    0.0345           0.4423        0.0180    0.2558   \n",
       "5       lt    0.0390           0.0255        0.0831    0.3435   \n",
       "6       ru    0.0336           0.0221        0.0700    0.3484   \n",
       "7       uk    0.0695           0.0641        0.0760    0.3748   \n",
       "\n",
       "   Macro Precision  Macro Recall  Macro F1 QALD  \n",
       "0           0.2930        0.2997         0.4436  \n",
       "1           0.3652        0.3813         0.5045  \n",
       "2           0.3709        0.3887         0.5183  \n",
       "3           0.3333        0.3534         0.4864  \n",
       "4           0.2564        0.2553         0.4036  \n",
       "5           0.3419        0.3600         0.5007  \n",
       "6           0.3465        0.3697         0.5043  \n",
       "7           0.3725        0.3935         0.5244  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://gerbil-qa.aksw.org/gerbil/experiment?id=202306270001\n",
    "baseline = pd.read_csv(\"../gerbil_results/mt5-base-qald9-dbpedia.csv\")\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the experience from experiment for Wikidata, we first pre-trained on LCquad 1.0 and fine-tuned on qald-9-plus with DBpedia SPARQLs.\n",
    "\n",
    "Since our entity linking tool for DBpedia only works for `en`, `de`, and `fr`, we only evaluated our model on these languages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gerbil-qa.aksw.org/gerbil/experiment?id=202306290000\n",
    "exp9 = pd.read_csv(\"../gerbil_results/mt5-lcquad-ling-qald9.csv\")\n",
    "exp9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mengshi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# Related work

## Unsupervised Feature-based Approaches

Learning applicable representations of words

- non-neural
  - Class-Based \textit{n}-gram Models of Natural Language
  - A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data
  - Domain Adaptation with Structural Correspondence Learning
- neural
  - Distributed Representations of Words and Phrases and Their Compositionality

## Unsupervised Fine-tunning Approaches

few parameters need to be learned from scratch

- left-to-right language modeling
- auto-encoder objectives

## Transfer Learning from Supervised Data

- natural language inference
- machine translation
- Computer vision

## Multilinguality in NLP Tasks

- multilingual word embeddings
  - Exploiting similarities among languages for machine translation
  - Unsupervised multilingual word embeddings.
  - Word transla- tion without parallel data
- learning cross-lingual Models
  - Unsupervised cross-lingual word embedding by multilingual neural language models
  - Cross-lingual language model pretraining
  - Unsupervised cross-lingual represen- tation learning at scale.
- multilingual translation
  - Multi-way, multilingual neural machine translation with a shared attention mechanism.
  - Googleâ€™s multilingual neural machine translation system: Enabling zero-shot translation.
  - Massively multilingual neural machine translation in the wild: Findings and challenges
- on low-resource languages
  - Universal neural machine translation for extremely low resource languages
